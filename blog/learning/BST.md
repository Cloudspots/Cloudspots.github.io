# 二叉搜索树学习笔记

## 简介

二叉搜索树（Binary Search Tree, BST）是一种有根的二叉树，每个节点有权值。满足其中序遍历为有序序列（空串也是有序的）。

或者这样定义：

1. 空树是二叉搜索树。
2. 对于一个节点 $a$，$a$ 的左子树和右子树都是二叉搜索树，并且满足：
   1. $a$ 的左子树中所有节点的权值都小于 $a$。
   2. $a$ 的右子树中所有节点的权值都大于 $a$。

利用二叉搜索树，我们可以实现一个“集合”类型（如 C++ STL 中 `std::set`）。若要支持可重集（如 C++ STL 中 `set::multiset`），可以再多一个卫星数据——出现次数。

为了方便，我们这里令一个节点 $k$ 的权值、左子结点、右子节点分别为 $k_v,k_l$ 和 $k_r$。令以一个节点 $k$ 为根的子树为 $T(k)$，而一棵树 $T$ 的大小记为 $s(T)$。

## 操作

注意，有些操作如果操作前/操作后 BST 为空，则可能需要特殊处理。很简单这里不讲了。

### 建树

什么都不需要干。

### 插入元素

显然，在二叉搜索树中可以这样插入元素：

1. 设定“当前节点 $g$”为根节点，要插入的元素权值为 $k$。
2. 进行分类讨论：
   1. 如果 $k=v(g)$，则说明元素已经存在，依据情况执行操作然后结束（如可重集则将卫星数据出现次数增加 $1$）。
   2. 如果 $k<v(g)$，则说明 $k$ 应当插入在 $g$ 左子树中，若 $g_l$ 存在则执行 $g \gets g_l$ 然后回到第二步，否则插入到 $g_l$ 的位置并结束。
   3. 如果 $k>v(g)$，则类似上面执行操作。

### 搜索元素

类似上面的“插入元素”，只不过在 $k=v(g)$ 时说明找到了元素，$k\neq v(g)$ 时如果对应左/右子结点不存在则说明没找到，并且不会插入元素。

### 查询最大/最小元素

只需要一直往左子结点走（查询最小）直到没有左子结点，或者一直往右子节点走（查询最大）直到没有右子节点即可。

同样，我们可以查询以某个节点为根节点的最大/最小值。

注意当一直往左（右）的时候走到一个只有右（左）子节点的节点的时候不能往右（左）走，因为那样会更大（小）。

### 删除元素

首先使用“搜索元素”找到对应元素 $g$（假设存在）。

然后看情况可能需要执行操作，也可能执行完退出（如，可重集对应出现次数 $>1$ 时，只需要把出现次数 $-1$ 并退出即可）。

如果没有退出，则执行如下操作：

1. 若 $g$ 是叶子结点：直接删除不会破坏任何性质。
2. 若 $g$ 是链节点（即只有左子树或右子树，不能都有或都没有）：用其唯一的子节点“代替”它（类似于在链表上删除节点 $g$）即可。
3. 若 $g$ 有两个子节点：显然，使用左子树中的最大节点/右子树中的最小节点代替它不会出现问题，以左子树为例，首先因为我们没有把节点的值变大所以对于右子树不会出现矛盾。然后因为这是左子树中的最大节点，左子树中的所有节点的权值都不大于它，所以对于左子树出现矛盾。于是我们把它的值变为左子树中的最大节点（或右子树中的最小节点，通常两个都行但是如果一个不存在则必须使用另一个），然后删除对应的最大/最小节点即可。删除操作仍然需要使用此过程（递归删除）。

### 查询元素排名

根据元素查询排名。

排名指的是第几小，下同。第几大也很简单。

**要支持这个，需要在维护上述信息的同时维护子树大小**（下同，如果提到了子树大小）。维护方法也很简单就不多说了。需要注意的是，如果维护的是可重集（并且使用附加数据域“出现次数”实现），统计子树大小的时候需要统计出现次数之和。

这个非常好想，在搜索元素的过程中，如果是走到右子树就把排名（初始为 $0$）加上 $s(T(g_l))+1$（$s(T(g_l))+1$ 就是 $g$ 的左子树大小），否则不变，找到的时候加上 $1$（或者直接初始化为 $1$）。

### 查询排名元素

根据排名查询元素。

“查询元素排名”的逆操作。我们只需要在搜索元素的过程中，如果排名 $=s(T(g_l))+1$（$s(T(g_l))$ 就是 $g$ 的左子树大小），则就是 $g$。如果小于，则往左子树搜索，排名不变。如果大于，则往右子树搜索，并且排名减少 $s(T(g_l))+1$。

如果是拓展的排名（即元素可能不存在，定义为比它小的元素个数 $+1$）则也相似，不多讲。

### 查询前驱/后继节点

查询一个值的前驱节点。也就是，最大的比它小的节点。后继类似，以前驱为例。

~~我们只需要在 BST 中，每次如果根节点和自己相同，则查询左子树的最大元素和当前记录的最小值的最小值。否则，如果自己的值比根节点小，则往左子树走。否则使用根节点更新最小值并往右走。~~

update：

> 由于我在代码实现的时候发现我对查询前驱/后继的分析要么过于复杂，要么不对。  
> 我想了一种更简单的做法，写完代码和代码一起贴上去。

是这样的，我们需要在满足小于某个数 $k$ 的所有节点中查询最大值。

那么从根节点开始，每次如果发现当前节点 $v(g)=k$ 则查询左子树的 $\max$，如果 $v(g)<k$ 则往左子树走（因为右子树中全都比它大），如果 $v(g)>k$，则如果右子树中存在前驱结点则直接返回右子树的前驱，否则返回 $g$。

可以使用递归实现，也可以记录一个 $\max$。我是用的是前者。

## 时间复杂度

~~正确性证明很显然，这里略去。~~

好了现在有不显然的一点了，关于查询前驱/后继的正确性证明？

容易发现，设 $h$ 为 BST 高度，则除去建树，所有操作的时间复杂度都是 $\mathcal O(h)$ 的（严格来讲加上建树也可以，但是有点魔怔）。

>
> 补充证明：为什么删除元素时间复杂度也是 $\mathcal O(h)$？
>
> 是这样的，实际上我们的操作有三/种情况：
>
> 1. （仅限于可重集）删除的节点的出现次数 $>1$：$\Theta(1)$ 地直接将出现次数 $-1$ 即可。
> 2. 如果是根节点：$\Theta(1)$ 地将二叉树清空。
> 3. 如果是叶子结点：$\Theta(1)$ 地直接删除。
> 4. 如果都不是：查询左子树的最大值或右子树的最小值替换自身，然后递归地删除对应节点。
>
> 最坏情况下，显然是一直执行第四种操作，这也是疑虑的来源。但是，替换时间复杂度是 $\Theta(1)$，而每次查询最大值/最小值都是一直向下走。也就是，最终会在树上走出一条路径，时间复杂度就是这条路径的长度，也就是 $\mathcal O(h)$。
>

所以说二叉搜索树的“平衡性”是一个问题，如果二叉树非常“瘦长”（比如极端情况退化成链），则时间复杂度也会退化（如链就是 $\mathcal O(n)$，相当于朴素算法，常数还更大）。

这个时候就需要引进各种平衡方法了，加上平衡方法的 BST 称为平衡树。

### 平衡树

- [Treap 学习笔记](待补)。
- [学习笔记 2](待补)。
- etc。

## 代码实现

```cpp
```
